{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb4d51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snt/projects_lujun/LabAgentSkill/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import datasets\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "logger = datasets.logging.get_logger(__name__)\n",
    "\n",
    "_CITATION = \"\"\"@inproceedings{loukas-etal-2022-finer,\n",
    "    title = \"{FiNER: Financial Numeric Entity Recognition for XBRL Tagging}\",\n",
    "    author = \"Loukas, Lefteris  and\n",
    "      Fergadiotis, Manos  and\n",
    "      Chalkidis, Ilias and\n",
    "      Spyropoulou, Eirini and\n",
    "      Malakasiotis, Prodromos  and\n",
    "      Androutsopoulos, Ion and\n",
    "      Paliouras George\",\n",
    "    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\",\n",
    "    month = \"may\",\n",
    "    year = \"2022\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "}\"\"\"\n",
    "\n",
    "_DESCRIPTION = \"\"\"\n",
    "FiNER-139 is a named entity recognition dataset consisting of 10K annual \n",
    "and quarterly English reports (filings) of publicly traded companies \n",
    "downloaded from the U.S. Securities and Exchange Commission (SEC) \n",
    "annotated with 139 XBRL tags in the IOB2 format.\n",
    "\"\"\"\n",
    "\n",
    "_DATA_URL = \"finer139.zip\"\n",
    "\n",
    "_HOMEPAGE = \"http://nlp.cs.aueb.gr/\"\n",
    "\n",
    "_VERSION = \"1.0.0\"\n",
    "\n",
    "_LABELS = [\n",
    "    \"O\",\n",
    "    \"B-AccrualForEnvironmentalLossContingencies\",\n",
    "    \"B-AcquiredFiniteLivedIntangibleAssetsWeightedAverageUsefulLife\",\n",
    "    \"I-AcquiredFiniteLivedIntangibleAssetsWeightedAverageUsefulLife\",\n",
    "    \"B-AllocatedShareBasedCompensationExpense\",\n",
    "    \"B-AmortizationOfFinancingCosts\",\n",
    "    \"B-AmortizationOfIntangibleAssets\",\n",
    "    \"I-AmortizationOfIntangibleAssets\",\n",
    "    \"B-AntidilutiveSecuritiesExcludedFromComputationOfEarningsPerShareAmount\",\n",
    "    \"I-AntidilutiveSecuritiesExcludedFromComputationOfEarningsPerShareAmount\",\n",
    "    \"B-AreaOfRealEstateProperty\",\n",
    "    \"I-AreaOfRealEstateProperty\",\n",
    "    \"B-AssetImpairmentCharges\",\n",
    "    \"B-BusinessAcquisitionEquityInterestsIssuedOrIssuableNumberOfSharesIssued\",\n",
    "    \"B-BusinessAcquisitionPercentageOfVotingInterestsAcquired\",\n",
    "    \"I-BusinessAcquisitionPercentageOfVotingInterestsAcquired\",\n",
    "    \"B-BusinessCombinationAcquisitionRelatedCosts\",\n",
    "    \"B-BusinessCombinationConsiderationTransferred1\",\n",
    "    \"B-BusinessCombinationContingentConsiderationLiability\",\n",
    "    \"B-BusinessCombinationRecognizedIdentifiableAssetsAcquiredAndLiabilitiesAssumedIntangibleAssetsOtherThanGoodwill\",\n",
    "    \"B-BusinessCombinationRecognizedIdentifiableAssetsAcquiredAndLiabilitiesAssumedIntangibles\",\n",
    "    \"B-CapitalizedContractCostAmortization\",\n",
    "    \"B-CashAndCashEquivalentsFairValueDisclosure\",\n",
    "    \"B-ClassOfWarrantOrRightExercisePriceOfWarrantsOrRights1\",\n",
    "    \"B-CommonStockCapitalSharesReservedForFutureIssuance\",\n",
    "    \"B-CommonStockDividendsPerShareDeclared\",\n",
    "    \"B-CommonStockParOrStatedValuePerShare\",\n",
    "    \"B-CommonStockSharesAuthorized\",\n",
    "    \"I-CommonStockSharesAuthorized\",\n",
    "    \"B-CommonStockSharesOutstanding\",\n",
    "    \"B-ConcentrationRiskPercentage1\",\n",
    "    \"B-ContractWithCustomerLiability\",\n",
    "    \"B-ContractWithCustomerLiabilityRevenueRecognized\",\n",
    "    \"B-CumulativeEffectOfNewAccountingPrincipleInPeriodOfAdoption\",\n",
    "    \"B-DebtInstrumentBasisSpreadOnVariableRate1\",\n",
    "    \"B-DebtInstrumentCarryingAmount\",\n",
    "    \"B-DebtInstrumentConvertibleConversionPrice1\",\n",
    "    \"B-DebtInstrumentFaceAmount\",\n",
    "    \"I-DebtInstrumentFaceAmount\",\n",
    "    \"B-DebtInstrumentFairValue\",\n",
    "    \"B-DebtInstrumentInterestRateEffectivePercentage\",\n",
    "    \"B-DebtInstrumentInterestRateStatedPercentage\",\n",
    "    \"B-DebtInstrumentMaturityDate\",\n",
    "    \"I-DebtInstrumentMaturityDate\",\n",
    "    \"B-DebtInstrumentRedemptionPricePercentage\",\n",
    "    \"B-DebtInstrumentTerm\",\n",
    "    \"I-DebtInstrumentTerm\",\n",
    "    \"B-DebtInstrumentUnamortizedDiscount\",\n",
    "    \"B-DebtWeightedAverageInterestRate\",\n",
    "    \"B-DeferredFinanceCostsGross\",\n",
    "    \"B-DeferredFinanceCostsNet\",\n",
    "    \"B-DefinedBenefitPlanContributionsByEmployer\",\n",
    "    \"B-DefinedContributionPlanCostRecognized\",\n",
    "    \"B-Depreciation\",\n",
    "    \"B-DerivativeFixedInterestRate\",\n",
    "    \"B-DerivativeNotionalAmount\",\n",
    "    \"B-DisposalGroupIncludingDiscontinuedOperationConsideration\",\n",
    "    \"B-EffectiveIncomeTaxRateContinuingOperations\",\n",
    "    \"B-EffectiveIncomeTaxRateReconciliationAtFederalStatutoryIncomeTaxRate\",\n",
    "    \"B-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognized\",\n",
    "    \"B-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognizedPeriodForRecognition1\",\n",
    "    \"I-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognizedPeriodForRecognition1\",\n",
    "    \"B-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognizedShareBasedAwardsOtherThanOptions\",\n",
    "    \"B-EmployeeServiceShareBasedCompensationTaxBenefitFromCompensationExpense\",\n",
    "    \"B-EquityMethodInvestmentOwnershipPercentage\",\n",
    "    \"I-EquityMethodInvestmentOwnershipPercentage\",\n",
    "    \"B-EquityMethodInvestments\",\n",
    "    \"B-FiniteLivedIntangibleAssetUsefulLife\",\n",
    "    \"I-FiniteLivedIntangibleAssetUsefulLife\",\n",
    "    \"B-GainsLossesOnExtinguishmentOfDebt\",\n",
    "    \"B-Goodwill\",\n",
    "    \"B-GoodwillImpairmentLoss\",\n",
    "    \"B-GuaranteeObligationsMaximumExposure\",\n",
    "    \"B-IncomeLossFromEquityMethodInvestments\",\n",
    "    \"B-IncomeTaxExpenseBenefit\",\n",
    "    \"B-InterestExpense\",\n",
    "    \"B-InterestExpenseDebt\",\n",
    "    \"B-LeaseAndRentalExpense\",\n",
    "    \"B-LesseeOperatingLeaseRenewalTerm\",\n",
    "    \"I-LesseeOperatingLeaseRenewalTerm\",\n",
    "    \"B-LesseeOperatingLeaseTermOfContract\",\n",
    "    \"I-LesseeOperatingLeaseTermOfContract\",\n",
    "    \"B-LettersOfCreditOutstandingAmount\",\n",
    "    \"B-LineOfCredit\",\n",
    "    \"B-LineOfCreditFacilityCommitmentFeePercentage\",\n",
    "    \"B-LineOfCreditFacilityCurrentBorrowingCapacity\",\n",
    "    \"B-LineOfCreditFacilityInterestRateAtPeriodEnd\",\n",
    "    \"B-LineOfCreditFacilityMaximumBorrowingCapacity\",\n",
    "    \"B-LineOfCreditFacilityRemainingBorrowingCapacity\",\n",
    "    \"B-LineOfCreditFacilityUnusedCapacityCommitmentFeePercentage\",\n",
    "    \"B-LongTermDebt\",\n",
    "    \"B-LongTermDebtFairValue\",\n",
    "    \"B-LossContingencyAccrualAtCarryingValue\",\n",
    "    \"B-LossContingencyDamagesSoughtValue\",\n",
    "    \"B-LossContingencyEstimateOfPossibleLoss\",\n",
    "    \"B-LossContingencyPendingClaimsNumber\",\n",
    "    \"I-LossContingencyPendingClaimsNumber\",\n",
    "    \"B-MinorityInterestOwnershipPercentageByNoncontrollingOwners\",\n",
    "    \"B-MinorityInterestOwnershipPercentageByParent\",\n",
    "    \"B-NumberOfOperatingSegments\",\n",
    "    \"B-NumberOfRealEstateProperties\",\n",
    "    \"I-NumberOfRealEstateProperties\",\n",
    "    \"B-NumberOfReportableSegments\",\n",
    "    \"B-OperatingLeaseCost\",\n",
    "    \"B-OperatingLeaseExpense\",\n",
    "    \"B-OperatingLeaseLiability\",\n",
    "    \"B-OperatingLeasePayments\",\n",
    "    \"B-OperatingLeaseRightOfUseAsset\",\n",
    "    \"B-OperatingLeaseWeightedAverageDiscountRatePercent\",\n",
    "    \"B-OperatingLeaseWeightedAverageRemainingLeaseTerm1\",\n",
    "    \"I-OperatingLeaseWeightedAverageRemainingLeaseTerm1\",\n",
    "    \"B-OperatingLeasesRentExpenseNet\",\n",
    "    \"B-OperatingLossCarryforwards\",\n",
    "    \"B-PaymentsToAcquireBusinessesGross\",\n",
    "    \"B-PaymentsToAcquireBusinessesNetOfCashAcquired\",\n",
    "    \"B-PreferredStockDividendRatePercentage\",\n",
    "    \"B-PreferredStockSharesAuthorized\",\n",
    "    \"I-PreferredStockSharesAuthorized\",\n",
    "    \"B-ProceedsFromIssuanceOfCommonStock\",\n",
    "    \"B-PropertyPlantAndEquipmentUsefulLife\",\n",
    "    \"I-PropertyPlantAndEquipmentUsefulLife\",\n",
    "    \"B-PublicUtilitiesRequestedRateIncreaseDecreaseAmount\",\n",
    "    \"B-RelatedPartyTransactionAmountsOfTransaction\",\n",
    "    \"I-RelatedPartyTransactionAmountsOfTransaction\",\n",
    "    \"B-RelatedPartyTransactionExpensesFromTransactionsWithRelatedParty\",\n",
    "    \"I-RelatedPartyTransactionExpensesFromTransactionsWithRelatedParty\",\n",
    "    \"B-RepaymentsOfDebt\",\n",
    "    \"B-RestructuringAndRelatedCostExpectedCost1\",\n",
    "    \"B-RestructuringCharges\",\n",
    "    \"B-RevenueFromContractWithCustomerExcludingAssessedTax\",\n",
    "    \"B-RevenueFromContractWithCustomerIncludingAssessedTax\",\n",
    "    \"B-RevenueFromRelatedParties\",\n",
    "    \"B-RevenueRemainingPerformanceObligation\",\n",
    "    \"B-Revenues\",\n",
    "    \"B-SaleOfStockNumberOfSharesIssuedInTransaction\",\n",
    "    \"I-SaleOfStockNumberOfSharesIssuedInTransaction\",\n",
    "    \"B-SaleOfStockPricePerShare\",\n",
    "    \"B-ShareBasedCompensation\",\n",
    "    \"B-ShareBasedCompensationArrangementByShareBasedPaymentAwardAwardVestingPeriod1\",\n",
    "    \"I-ShareBasedCompensationArrangementByShareBasedPaymentAwardAwardVestingPeriod1\",\n",
    "    \"B-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsGrantsInPeriod\",\n",
    "    \"I-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsGrantsInPeriod\",\n",
    "    \"B-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsGrantsInPeriodWeightedAverageGrantDateFairValue\",\n",
    "    \"B-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsNonvestedNumber\",\n",
    "    \"B-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsVestedInPeriodTotalFairValue\",\n",
    "    \"B-ShareBasedCompensationArrangementByShareBasedPaymentAwardNumberOfSharesAuthorized\",\n",
    "    \"I-ShareBasedCompensationArrangementByShareBasedPaymentAwardNumberOfSharesAuthorized\",\n",
    "    \"B-ShareBasedCompensationArrangementByShareBasedPaymentAwardNumberOfSharesAvailableForGrant\",\n",
    "    \"B-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsExercisesInPeriodTotalIntrinsicValue\",\n",
    "    \"B-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsGrantsInPeriodGross\",\n",
    "    \"B-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsGrantsInPeriodWeightedAverageGrantDateFairValue\",\n",
    "    \"B-SharePrice\",\n",
    "    \"B-SharebasedCompensationArrangementBySharebasedPaymentAwardAwardVestingRightsPercentage\",\n",
    "    \"I-SharebasedCompensationArrangementBySharebasedPaymentAwardAwardVestingRightsPercentage\",\n",
    "    \"B-SharebasedCompensationArrangementBySharebasedPaymentAwardExpirationPeriod\",\n",
    "    \"I-SharebasedCompensationArrangementBySharebasedPaymentAwardExpirationPeriod\",\n",
    "    \"B-StockIssuedDuringPeriodSharesNewIssues\",\n",
    "    \"I-StockIssuedDuringPeriodSharesNewIssues\",\n",
    "    \"B-StockRepurchaseProgramAuthorizedAmount1\",\n",
    "    \"B-StockRepurchaseProgramRemainingAuthorizedRepurchaseAmount1\",\n",
    "    \"B-StockRepurchasedAndRetiredDuringPeriodShares\",\n",
    "    \"B-StockRepurchasedDuringPeriodShares\",\n",
    "    \"I-StockRepurchasedDuringPeriodShares\",\n",
    "    \"B-SupplementalInformationForPropertyCasualtyInsuranceUnderwritersPriorYearClaimsAndClaimsAdjustmentExpense\",\n",
    "    \"B-TreasuryStockAcquiredAverageCostPerShare\",\n",
    "    \"B-TreasuryStockSharesAcquired\",\n",
    "    \"I-TreasuryStockSharesAcquired\",\n",
    "    \"B-TreasuryStockValueAcquiredCostMethod\",\n",
    "    \"B-UnrecognizedTaxBenefits\",\n",
    "    \"B-UnrecognizedTaxBenefitsThatWouldImpactEffectiveTaxRate\",\n",
    "    \"I-DeferredFinanceCostsGross\",\n",
    "    \"I-CommonStockParOrStatedValuePerShare\",\n",
    "    \"I-LossContingencyEstimateOfPossibleLoss\",\n",
    "    \"I-DefinedContributionPlanCostRecognized\",\n",
    "    \"I-DebtInstrumentFairValue\",\n",
    "    \"I-ContractWithCustomerLiabilityRevenueRecognized\",\n",
    "    \"I-RevenueRemainingPerformanceObligation\",\n",
    "    \"I-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognized\",\n",
    "    \"I-DebtInstrumentInterestRateStatedPercentage\",\n",
    "    \"I-OperatingLossCarryforwards\",\n",
    "    \"I-MinorityInterestOwnershipPercentageByNoncontrollingOwners\",\n",
    "    \"I-InterestExpense\",\n",
    "    \"I-LongTermDebt\",\n",
    "    \"I-ShareBasedCompensation\",\n",
    "    \"I-DebtWeightedAverageInterestRate\",\n",
    "    \"I-DebtInstrumentCarryingAmount\",\n",
    "    \"I-DebtInstrumentConvertibleConversionPrice1\",\n",
    "    \"I-IncomeTaxExpenseBenefit\",\n",
    "    \"I-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsGrantsInPeriodWeightedAverageGrantDateFairValue\",\n",
    "    \"I-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognizedShareBasedAwardsOtherThanOptions\",\n",
    "    \"I-EquityMethodInvestments\",\n",
    "    \"I-DebtInstrumentUnamortizedDiscount\",\n",
    "    \"I-GainsLossesOnExtinguishmentOfDebt\",\n",
    "    \"I-ShareBasedCompensationArrangementByShareBasedPaymentAwardNumberOfSharesAvailableForGrant\",\n",
    "    \"I-BusinessCombinationRecognizedIdentifiableAssetsAcquiredAndLiabilitiesAssumedIntangibleAssetsOtherThanGoodwill\",\n",
    "    \"I-PreferredStockDividendRatePercentage\",\n",
    "    \"I-RevenueFromContractWithCustomerIncludingAssessedTax\",\n",
    "    \"I-OperatingLeaseWeightedAverageDiscountRatePercent\",\n",
    "    \"I-LineOfCredit\",\n",
    "    \"I-LineOfCreditFacilityMaximumBorrowingCapacity\",\n",
    "    \"I-EffectiveIncomeTaxRateReconciliationAtFederalStatutoryIncomeTaxRate\",\n",
    "    \"I-LineOfCreditFacilityCommitmentFeePercentage\",\n",
    "    \"I-BusinessCombinationConsiderationTransferred1\",\n",
    "    \"I-CommonStockDividendsPerShareDeclared\",\n",
    "    \"I-DebtInstrumentBasisSpreadOnVariableRate1\",\n",
    "    \"I-DisposalGroupIncludingDiscontinuedOperationConsideration\",\n",
    "    \"I-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsGrantsInPeriodGross\",\n",
    "    \"I-CommonStockSharesOutstanding\",\n",
    "    \"I-AmortizationOfFinancingCosts\",\n",
    "    \"I-LineOfCreditFacilityCurrentBorrowingCapacity\",\n",
    "    \"I-TreasuryStockValueAcquiredCostMethod\",\n",
    "    \"I-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsNonvestedNumber\",\n",
    "    \"I-DebtInstrumentInterestRateEffectivePercentage\",\n",
    "    \"I-SaleOfStockPricePerShare\",\n",
    "    \"I-CapitalizedContractCostAmortization\",\n",
    "    \"I-RestructuringCharges\",\n",
    "    \"I-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsVestedInPeriodTotalFairValue\",\n",
    "    \"I-AccrualForEnvironmentalLossContingencies\",\n",
    "    \"I-CashAndCashEquivalentsFairValueDisclosure\",\n",
    "    \"I-ProceedsFromIssuanceOfCommonStock\",\n",
    "    \"I-Revenues\",\n",
    "    \"I-BusinessCombinationRecognizedIdentifiableAssetsAcquiredAndLiabilitiesAssumedIntangibles\",\n",
    "    \"I-LettersOfCreditOutstandingAmount\",\n",
    "    \"I-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsGrantsInPeriodWeightedAverageGrantDateFairValue\",\n",
    "    \"I-OperatingLeasePayments\",\n",
    "    \"I-LineOfCreditFacilityRemainingBorrowingCapacity\",\n",
    "    \"I-PaymentsToAcquireBusinessesGross\",\n",
    "    \"I-TreasuryStockAcquiredAverageCostPerShare\",\n",
    "    \"I-DeferredFinanceCostsNet\",\n",
    "    \"I-StockRepurchaseProgramAuthorizedAmount1\",\n",
    "    \"I-InterestExpenseDebt\",\n",
    "    \"I-ContractWithCustomerLiability\",\n",
    "    \"I-OperatingLeaseExpense\",\n",
    "    \"I-Depreciation\",\n",
    "    \"I-AllocatedShareBasedCompensationExpense\",\n",
    "    \"I-LossContingencyAccrualAtCarryingValue\",\n",
    "    \"I-LineOfCreditFacilityUnusedCapacityCommitmentFeePercentage\",\n",
    "    \"I-SupplementalInformationForPropertyCasualtyInsuranceUnderwritersPriorYearClaimsAndClaimsAdjustmentExpense\",\n",
    "    \"I-OperatingLeaseLiability\",\n",
    "    \"I-RevenueFromRelatedParties\",\n",
    "    \"I-PaymentsToAcquireBusinessesNetOfCashAcquired\",\n",
    "    \"I-BusinessCombinationContingentConsiderationLiability\",\n",
    "    \"I-LossContingencyDamagesSoughtValue\",\n",
    "    \"I-NumberOfOperatingSegments\",\n",
    "    \"I-BusinessAcquisitionEquityInterestsIssuedOrIssuableNumberOfSharesIssued\",\n",
    "    \"I-OperatingLeaseRightOfUseAsset\",\n",
    "    \"I-BusinessCombinationAcquisitionRelatedCosts\",\n",
    "    \"I-UnrecognizedTaxBenefits\",\n",
    "    \"I-GuaranteeObligationsMaximumExposure\",\n",
    "    \"I-RestructuringAndRelatedCostExpectedCost1\",\n",
    "    \"I-DefinedBenefitPlanContributionsByEmployer\",\n",
    "    \"I-OperatingLeaseCost\",\n",
    "    \"I-DerivativeFixedInterestRate\",\n",
    "    \"I-Goodwill\",\n",
    "    \"I-GoodwillImpairmentLoss\",\n",
    "    \"I-CommonStockCapitalSharesReservedForFutureIssuance\",\n",
    "    \"I-StockRepurchasedAndRetiredDuringPeriodShares\",\n",
    "    \"I-EmployeeServiceShareBasedCompensationTaxBenefitFromCompensationExpense\",\n",
    "    \"I-IncomeLossFromEquityMethodInvestments\",\n",
    "    \"I-NumberOfReportableSegments\",\n",
    "    \"I-LongTermDebtFairValue\",\n",
    "    \"I-RepaymentsOfDebt\",\n",
    "    \"I-ConcentrationRiskPercentage1\",\n",
    "    \"I-DebtInstrumentRedemptionPricePercentage\",\n",
    "    \"I-CumulativeEffectOfNewAccountingPrincipleInPeriodOfAdoption\",\n",
    "    \"I-SharePrice\",\n",
    "    \"I-UnrecognizedTaxBenefitsThatWouldImpactEffectiveTaxRate\",\n",
    "    \"I-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsExercisesInPeriodTotalIntrinsicValue\",\n",
    "    \"I-EffectiveIncomeTaxRateContinuingOperations\",\n",
    "    \"I-RevenueFromContractWithCustomerExcludingAssessedTax\",\n",
    "    \"I-StockRepurchaseProgramRemainingAuthorizedRepurchaseAmount1\",\n",
    "    \"I-LineOfCreditFacilityInterestRateAtPeriodEnd\",\n",
    "    \"I-ClassOfWarrantOrRightExercisePriceOfWarrantsOrRights1\",\n",
    "    \"I-OperatingLeasesRentExpenseNet\",\n",
    "    \"I-LeaseAndRentalExpense\",\n",
    "    \"I-PublicUtilitiesRequestedRateIncreaseDecreaseAmount\",\n",
    "    \"I-MinorityInterestOwnershipPercentageByParent\",\n",
    "    \"I-AssetImpairmentCharges\",\n",
    "    \"I-DerivativeNotionalAmount\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2acdbfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_set = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43massets/datasets/finer-139/train.jsonl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m test_set = pd.read_json(\u001b[33m\"\u001b[39m\u001b[33massets/datasets/finer-139/test.jsonl\u001b[39m\u001b[33m\"\u001b[39m, lines = \u001b[38;5;28;01mTrue\u001b[39;00m)     \n\u001b[32m      4\u001b[39m val_set = pd.read_json(\u001b[33m\"\u001b[39m\u001b[33massets/datasets/finer-139/validation.jsonl\u001b[39m\u001b[33m\"\u001b[39m, lines = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects_lujun/LabAgentSkill/.venv/lib/python3.12/site-packages/pandas/io/json/_json.py:829\u001b[39m, in \u001b[36mread_json\u001b[39m\u001b[34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[39m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient != \u001b[33m\"\u001b[39m\u001b[33mtable\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    827\u001b[39m     convert_axes = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m json_reader = \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[32m    851\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects_lujun/LabAgentSkill/.venv/lib/python3.12/site-packages/pandas/io/json/_json.py:936\u001b[39m, in \u001b[36mJsonReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[39m\n\u001b[32m    934\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.chunksize \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nrows):\n\u001b[32m    935\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m936\u001b[39m         \u001b[38;5;28mself\u001b[39m.data = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    938\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:322\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_set = pd.read_json(\"assets/datasets/finer-139/train.jsonl\", lines = True)\n",
    "\n",
    "test_set = pd.read_json(\"assets/datasets/finer-139/test.jsonl\", lines = True)     \n",
    "val_set = pd.read_json(\"assets/datasets/finer-139/validation.jsonl\", lines = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7668503",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[\"label_split\"] = \"train\"\n",
    "test_set[\"label_split\"] = \"test\"\n",
    "val_set[\"label_split\"] = \"validation\"\n",
    "\n",
    "def get_XBRL_tags(ner_tags_list, tag_list=_LABELS):\n",
    "    non_zero_tags = []\n",
    "    index = 0\n",
    "    tag_indices = []    \n",
    "    for tag in ner_tags_list:\n",
    "        if tag != 'O':\n",
    "            if tag in tag_list:\n",
    "                non_zero_tags.append(tag)\n",
    "                tag_indices.append(index)\n",
    "\n",
    "            else:\n",
    "                logger.warning(f\"Tag {tag} not found in tag list.\")\n",
    "        index += 1\n",
    "        \n",
    "    return non_zero_tags, tag_indices\n",
    "\n",
    "\n",
    "train_set[\"tag_names\"], train_set[\"tag_indices\"] = zip(*train_set[\"ner_tags\"].apply(get_XBRL_tags))\n",
    "test_set[\"tag_names\"], test_set[\"tag_indices\"] = zip(*test_set[\"ner_tags\"].apply(get_XBRL_tags))\n",
    "val_set[\"tag_names\"], val_set[\"tag_indices\"] = zip(*val_set[\"ner_tags\"].apply(get_XBRL_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbe22c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Converting to HuggingFace Dataset Format\n",
      "============================================================\n",
      "Converting train set...\n",
      "Converting test set...\n",
      "Converting validation set...\n",
      "\n",
      "‚úì Dataset conversion complete!\n",
      "  Train: 900384 examples\n",
      "  Test: 108378 examples\n",
      "  Validation: 112494 examples\n",
      "\n",
      "‚úì Features: ['id', 'tokens', 'ner_tags', 'tag_names', 'tag_indices', 'label_split']\n",
      "\n",
      "============================================================\n",
      "Sample from dataset:\n",
      "============================================================\n",
      "ID: 0\n",
      "Tokens: ['ITEM', '1', 'Financial', 'Statements', 'Lennar', 'Corporation', 'and', 'Subsidiaries', 'Condensed', 'Consolidated', 'Balance', 'Sheets', '(', 'Dollars', 'in']\n",
      "NER Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Tag Names: ['B-EquityMethodInvestments', 'B-EquityMethodInvestments']\n",
      "Tag Indices: [180, 293]\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrames to HuggingFace Dataset and upload to Hub\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Converting to HuggingFace Dataset Format\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from datasets import Dataset, DatasetDict, Features, Sequence, Value\n",
    "\n",
    "# Convert each pandas dataframe to HuggingFace Dataset\n",
    "def df_to_hf_dataset(df):\n",
    "    \"\"\"Convert pandas DataFrame to HuggingFace Dataset\"\"\"\n",
    "    data_dict = {\n",
    "        \"id\": df[\"id\"].tolist(),\n",
    "        \"tokens\": df[\"tokens\"].tolist(),\n",
    "        \"ner_tags\": df[\"ner_tags\"].tolist(),\n",
    "        \"tag_names\": df[\"tag_names\"].tolist(),\n",
    "        \"tag_indices\": df[\"tag_indices\"].tolist(),\n",
    "        \"label_split\": df[\"label_split\"].tolist()\n",
    "    }\n",
    "    return data_dict\n",
    "\n",
    "# Create datasets\n",
    "print(\"Converting train set...\")\n",
    "train_data = df_to_hf_dataset(train_set)\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "\n",
    "print(\"Converting test set...\")\n",
    "test_data = df_to_hf_dataset(test_set)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "\n",
    "print(\"Converting validation set...\")\n",
    "val_data = df_to_hf_dataset(val_set)\n",
    "val_dataset = Dataset.from_dict(val_data)\n",
    "\n",
    "# Combine into DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset,\n",
    "    \"validation\": val_dataset\n",
    "})\n",
    "\n",
    "print(f\"\\n‚úì Dataset conversion complete!\")\n",
    "print(f\"  Train: {len(train_dataset)} examples\")\n",
    "print(f\"  Test: {len(test_dataset)} examples\")\n",
    "print(f\"  Validation: {len(val_dataset)} examples\")\n",
    "print(f\"\\n‚úì Features: {dataset_dict['train'].column_names}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Sample from dataset:\")\n",
    "print(\"=\"*60)\n",
    "sample = train_dataset[0]\n",
    "print(f\"ID: {sample['id']}\")\n",
    "print(f\"Tokens: {sample['tokens'][:15]}\")\n",
    "print(f\"NER Tags: {sample['ner_tags'][:15]}\")\n",
    "print(f\"Tag Names: {sample['tag_names']}\")\n",
    "print(f\"Tag Indices: {sample['tag_indices']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7c5e123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Upload to HuggingFace Hub\n",
      "============================================================\n",
      "\n",
      "STEP 1: Install and authenticate HuggingFace CLI\n",
      "======================================================\n",
      "# Install if not already installed\n",
      "pip install huggingface-hub\n",
      "\n",
      "# Authenticate with your HuggingFace token\n",
      "huggingface-cli login\n",
      "# or programmatically:\n",
      "\n",
      "\n",
      "STEP 2: Configure your dataset repo name\n",
      "============================================================\n",
      "\n",
      "Choose a repo name format:\n",
      "  - finer-139-standardized (recommended)\n",
      "  - financial-ner-xbrl-139\n",
      "  - finer139-with-tags\n",
      "\n",
      "Update the repo_id below with your username:\n",
      "  repo_id = \"volavion/finer-139-std\"\n",
      "\n",
      "\n",
      "Configured repository: volavion/finer-139-std\n",
      "Privacy: Public\n",
      "\n",
      "STEP 3: Push dataset to Hub\n",
      "============================================================\n",
      "\n",
      "# Push to HuggingFace Hub\n",
      "try:\n",
      "    # Uncomment after setting REPO_ID with your username\n",
      "    # login()  # Authenticate first\n",
      "\n",
      "    dataset_dict.push_to_hub(\n",
      "        repo_id=\"volavion/finer-139-std\",\n",
      "        private=False,\n",
      "        commit_message=\"Upload standardized FiNER-139 dataset with XBRL tags\"\n",
      "    )\n",
      "    print(\"‚úì Dataset uploaded successfully!\")\n",
      "    print(f\"‚úì View at: https://huggingface.co/datasets/volavion/finer-139-std\")\n",
      "\n",
      "except Exception as e:\n",
      "    print(f\"‚úó Upload failed: {e}\")\n",
      "    print(\"Please check:\")\n",
      "    print(\"  1. REPO_ID is set correctly (replace 'your-username')\")\n",
      "    print(\"  2. You are authenticated: huggingface-cli login\")\n",
      "    print(\"  3. Your token has write permissions\")\n",
      "\n",
      "\n",
      "STEP 4: Verify upload\n",
      "============================================================\n",
      "\n",
      "# Test loading your dataset\n",
      "from datasets import load_dataset\n",
      "dataset = load_dataset(\"your-username/finer-139-standardized\")\n",
      "print(dataset)\n",
      "\n",
      "\n",
      "DATASET STATISTICS:\n",
      "============================================================\n",
      "  Total examples: 1121256\n",
      "  Train split: 900384 examples\n",
      "  Test split: 108378 examples\n",
      "  Validation split: 112494 examples\n",
      "  Features: id, tokens, ner_tags, tag_names, tag_indices, label_split\n",
      "  XBRL tags: 279 total tags\n",
      "\n",
      "‚úì Ready to upload! Execute the code above with your HuggingFace token.\n"
     ]
    }
   ],
   "source": [
    "# Upload standardized dataset to HuggingFace Hub\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Upload to HuggingFace Hub\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "STEP 1: Install and authenticate HuggingFace CLI\n",
    "======================================================\n",
    "# Install if not already installed\n",
    "pip install huggingface-hub\n",
    "\n",
    "# Authenticate with your HuggingFace token\n",
    "huggingface-cli login\n",
    "# or programmatically:\n",
    "\"\"\")\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "print(\"\\nSTEP 2: Configure your dataset repo name\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "Choose a repo name format:\n",
    "  - finer-139-standardized (recommended)\n",
    "  - financial-ner-xbrl-139\n",
    "  - finer139-with-tags\n",
    "\n",
    "Update the repo_id below with your username:\n",
    "  repo_id = \"volavion/finer-139-std\"\n",
    "\"\"\")\n",
    "\n",
    "# CONFIGURATION - Update these before running\n",
    "REPO_ID = \"volavion/finer-139-std\"  # Replace with your actual repo\n",
    "PRIVATE = False  # Set to True for private dataset\n",
    "\n",
    "print(f\"\\nConfigured repository: {REPO_ID}\")\n",
    "print(f\"Privacy: {'Private' if PRIVATE else 'Public'}\")\n",
    "\n",
    "print(\"\\nSTEP 3: Push dataset to Hub\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "push_code = f'''\n",
    "# Push to HuggingFace Hub\n",
    "try:\n",
    "    # Uncomment after setting REPO_ID with your username\n",
    "    # login()  # Authenticate first\n",
    "    \n",
    "    dataset_dict.push_to_hub(\n",
    "        repo_id=\"{REPO_ID}\",\n",
    "        private={PRIVATE},\n",
    "        commit_message=\"Upload standardized FiNER-139 dataset with XBRL tags\"\n",
    "    )\n",
    "    print(\"‚úì Dataset uploaded successfully!\")\n",
    "    print(f\"‚úì View at: https://huggingface.co/datasets/{REPO_ID}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó Upload failed: {{e}}\")\n",
    "    print(\"Please check:\")\n",
    "    print(\"  1. REPO_ID is set correctly (replace 'your-username')\")\n",
    "    print(\"  2. You are authenticated: huggingface-cli login\")\n",
    "    print(\"  3. Your token has write permissions\")\n",
    "'''\n",
    "\n",
    "print(push_code)\n",
    "\n",
    "print(\"\\nSTEP 4: Verify upload\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "# Test loading your dataset\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"your-username/finer-139-standardized\")\n",
    "print(dataset)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nDATASET STATISTICS:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Total examples: {len(train_dataset) + len(test_dataset) + len(val_dataset)}\")\n",
    "print(f\"  Train split: {len(train_dataset)} examples\")\n",
    "print(f\"  Test split: {len(test_dataset)} examples\")\n",
    "print(f\"  Validation split: {len(val_dataset)} examples\")\n",
    "print(f\"  Features: {', '.join(dataset_dict['train'].column_names)}\")\n",
    "print(f\"  XBRL tags: {len(_LABELS)} total tags\")\n",
    "\n",
    "print(\"\\n‚úì Ready to upload! Execute the code above with your HuggingFace token.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "952285c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "UPLOADING DATASET TO HUGGINGFACE HUB\n",
      "======================================================================\n",
      "\n",
      "üìä Dataset Details:\n",
      "  Repo ID: Volavion/finer-139-std\n",
      "  Privacy: üåê Public\n",
      "  Train examples: 900384\n",
      "  Test examples: 108378\n",
      "  Validation examples: 112494\n",
      "  Total: 1121256 examples\n",
      "\n",
      "üîê Step 1: Authenticating with HuggingFace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.77ba/s]\n",
      "Processing Files (1 / 1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38.2MB / 38.2MB,  0.00B/s  \n",
      "New Data Upload: |          |  0.00B /  0.00B,  0.00B/s  \n",
      "Creating parquet from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.75ba/s]\n",
      "Processing Files (1 / 1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38.1MB / 38.1MB,  0.00B/s  \n",
      "New Data Upload: |          |  0.00B /  0.00B,  0.00B/s  \n",
      "Uploading the dataset shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.89s/ shards]\n",
      "Creating parquet from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.84ba/s]\n",
      "Processing Files (1 / 1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.77MB / 9.77MB,  0.00B/s  \n",
      "New Data Upload: |          |  0.00B /  0.00B,  0.00B/s  \n",
      "Uploading the dataset shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.48s/ shards]\n",
      "Creating parquet from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.70ba/s]\n",
      "Processing Files (1 / 1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.97MB / 9.97MB,  0.00B/s  \n",
      "New Data Upload: |          |  0.00B /  0.00B,  0.00B/s  \n",
      "Uploading the dataset shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.26s/ shards]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ SUCCESS! Dataset uploaded to HuggingFace Hub\n",
      "\n",
      "üîó Dataset URL: https://huggingface.co/datasets/Volavion/finer-139-std\n",
      "\n",
      "üìù Dataset card has been created. You can edit it on HuggingFace Hub.\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Execute: Upload Dataset to HuggingFace Hub using Token\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load ANTHROPIC_API_KEY from .env without printing it\n",
    "env_path = Path.cwd().parent / \".env\" if Path.cwd().name == \"notebooks\" else Path.cwd() / \".env\"\n",
    "if env_path.exists():\n",
    "    for line in env_path.read_text().splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\") or \"=\" not in line:\n",
    "            continue\n",
    "        key, value = line.split(\"=\", 1)\n",
    "        key = key.strip()\n",
    "        value = value.strip()\n",
    "        if key and key not in os.environ:\n",
    "            os.environ[key] = value\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"UPLOADING DATASET TO HUGGINGFACE HUB\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from huggingface_hub import login\n",
    "import getpass\n",
    "\n",
    "hf_token = os.environ.get(\"HUGGINGFACE_HUB_TOKEN\", \"\")  # Initialize token variable\n",
    "\n",
    "# Configuration\n",
    "REPO_ID = \"Volavion/finer-139-std\"\n",
    "PRIVATE = False\n",
    "\n",
    "print(f\"\\nüìä Dataset Details:\")\n",
    "print(f\"  Repo ID: {REPO_ID}\")\n",
    "print(f\"  Privacy: {'üîí Private' if PRIVATE else 'üåê Public'}\")\n",
    "print(f\"  Train examples: {len(train_dataset)}\")\n",
    "print(f\"  Test examples: {len(test_dataset)}\")\n",
    "print(f\"  Validation examples: {len(val_dataset)}\")\n",
    "print(f\"  Total: {len(train_dataset) + len(test_dataset) + len(val_dataset)} examples\")\n",
    "\n",
    "print(f\"\\nüîê Step 1: Authenticating with HuggingFace...\")\n",
    "\n",
    "\n",
    "try:\n",
    "    # Push dataset to hub\n",
    "    dataset_dict.push_to_hub(\n",
    "        repo_id=REPO_ID,\n",
    "        private=PRIVATE,\n",
    "        commit_message=\"Upload standardized FiNER-139 dataset with XBRL tags\\n\\n- 139 XBRL financial tags\\n- Train/Test/Validation splits\\n- Token labels and tag names included\",\n",
    "        token=hf_token if hf_token.strip() else None\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ SUCCESS! Dataset uploaded to HuggingFace Hub\")\n",
    "    print(f\"\\nüîó Dataset URL: https://huggingface.co/datasets/{REPO_ID}\")\n",
    "    print(f\"\\nüìù Dataset card has been created. You can edit it on HuggingFace Hub.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Upload failed with error:\")\n",
    "    print(f\"  {type(e).__name__}: {e}\")\n",
    "    print(f\"\\nüí° Troubleshooting:\")\n",
    "    print(f\"  1. Check your HuggingFace token is valid\")\n",
    "    print(f\"  2. Ensure you have write permissions\")\n",
    "    print(f\"  3. The repo_id '{REPO_ID}' must match your username\")\n",
    "    print(f\"  4. Try: huggingface-cli login\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "032d9677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Converting to HuggingFace Dataset Format\n",
      "============================================================\n",
      "Converting train set...\n",
      "Converting test set...\n",
      "Converting validation set...\n"
     ]
    }
   ],
   "source": [
    "train_set_shortened = train_set[train_set[\"tag_names\"].apply(lambda x: len(x) > 0)]\n",
    "test_set_shortened = test_set[test_set[\"tag_names\"].apply(lambda x: len(x) > 0)]\n",
    "val_set_shortened = val_set[val_set[\"tag_names\"].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# Convert pandas DataFrames to HuggingFace Dataset and upload to Hub\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Converting to HuggingFace Dataset Format\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from datasets import Dataset, DatasetDict, Features, Sequence, Value\n",
    "\n",
    "# Convert each pandas dataframe to HuggingFace Dataset\n",
    "def df_to_hf_dataset(df):\n",
    "    \"\"\"Convert pandas DataFrame to HuggingFace Dataset\"\"\"\n",
    "    data_dict = {\n",
    "        \"id\": df[\"id\"].tolist(),\n",
    "        \"tokens\": df[\"tokens\"].tolist(),\n",
    "        \"ner_tags\": df[\"ner_tags\"].tolist(),\n",
    "        \"tag_names\": df[\"tag_names\"].tolist(),\n",
    "        \"tag_indices\": df[\"tag_indices\"].tolist(),\n",
    "        \"label_split\": df[\"label_split\"].tolist()\n",
    "    }\n",
    "    return data_dict\n",
    "\n",
    "# Create datasets\n",
    "print(\"Converting train set...\")\n",
    "train_data = df_to_hf_dataset(train_set_shortened)\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "\n",
    "print(\"Converting test set...\")\n",
    "test_data = df_to_hf_dataset(test_set_shortened)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "\n",
    "print(\"Converting validation set...\")\n",
    "val_data = df_to_hf_dataset(val_set_shortened)\n",
    "val_dataset = Dataset.from_dict(val_data)\n",
    "\n",
    "# Combine into DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset,\n",
    "    \"validation\": val_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af4698a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "UPLOADING DATASET TO HUGGINGFACE HUB\n",
      "======================================================================\n",
      "\n",
      "üìä Dataset Details:\n",
      "  Repo ID: Volavion/finer-139-xbrl-nonempty\n",
      "  Privacy: üåê Public\n",
      "  Train examples: 179195\n",
      "  Test examples: 18789\n",
      "  Validation examples: 21603\n",
      "  Total: 219587 examples\n",
      "\n",
      "üîê Step 1: Authenticating with HuggingFace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.86ba/s]\n",
      "Processing Files (1 / 1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.4MB / 17.4MB,  0.00B/s  \n",
      "New Data Upload: |          |  0.00B /  0.00B,  0.00B/s  \n",
      "Uploading the dataset shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.47s/ shards]\n",
      "Creating parquet from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.24ba/s]\n",
      "Processing Files (1 / 1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.03MB / 2.03MB,  0.00B/s  \n",
      "New Data Upload: |          |  0.00B /  0.00B,  0.00B/s  \n",
      "Uploading the dataset shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.43 shards/s]\n",
      "Creating parquet from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.62ba/s]\n",
      "Processing Files (1 / 1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.33MB / 2.33MB,  0.00B/s  \n",
      "New Data Upload: |          |  0.00B /  0.00B,  0.00B/s  \n",
      "Uploading the dataset shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.30 shards/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ SUCCESS! Dataset uploaded to HuggingFace Hub\n",
      "\n",
      "üîó Dataset URL: https://huggingface.co/datasets/Volavion/finer-139-xbrl-nonempty\n",
      "\n",
      "üìù Dataset card has been created. You can edit it on HuggingFace Hub.\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Upload standardized dataset to HuggingFace Hub\n",
    "# CONFIGURATION - Update these before running\n",
    "REPO_ID = \"Volavion/finer-139-xbrl-nonempty\"  # Replace with your actual repo\n",
    "PRIVATE = False  # Set to True for private dataset\n",
    "\n",
    "# Execute: Upload Dataset to HuggingFace Hub using Token\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load ANTHROPIC_API_KEY from .env without printing it\n",
    "env_path = Path.cwd().parent / \".env\" if Path.cwd().name == \"notebooks\" else Path.cwd() / \".env\"\n",
    "if env_path.exists():\n",
    "    for line in env_path.read_text().splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\") or \"=\" not in line:\n",
    "            continue\n",
    "        key, value = line.split(\"=\", 1)\n",
    "        key = key.strip()\n",
    "        value = value.strip()\n",
    "        if key and key not in os.environ:\n",
    "            os.environ[key] = value\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"UPLOADING DATASET TO HUGGINGFACE HUB\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from huggingface_hub import login\n",
    "import getpass\n",
    "\n",
    "hf_token = os.environ.get(\"HUGGINGFACE_HUB_TOKEN\", \"\")  # Initialize token variable\n",
    "\n",
    "\n",
    "print(f\"\\nüìä Dataset Details:\")\n",
    "print(f\"  Repo ID: {REPO_ID}\")\n",
    "print(f\"  Privacy: {'üîí Private' if PRIVATE else 'üåê Public'}\")\n",
    "print(f\"  Train examples: {len(train_dataset)}\")\n",
    "print(f\"  Test examples: {len(test_dataset)}\")\n",
    "print(f\"  Validation examples: {len(val_dataset)}\")\n",
    "print(f\"  Total: {len(train_dataset) + len(test_dataset) + len(val_dataset)} examples\")\n",
    "\n",
    "print(f\"\\nüîê Step 1: Authenticating with HuggingFace...\")\n",
    "\n",
    "\n",
    "try:\n",
    "    # Push dataset to hub\n",
    "    dataset_dict.push_to_hub(\n",
    "        repo_id=REPO_ID,\n",
    "        private=PRIVATE,\n",
    "        commit_message=\"Upload standardized FiNER-139 dataset with XBRL tags\\n\\n- 139 XBRL financial tags\\n- Train/Test/Validation splits\\n- Token labels and tag names included\",\n",
    "        token=hf_token if hf_token.strip() else None\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ SUCCESS! Dataset uploaded to HuggingFace Hub\")\n",
    "    print(f\"\\nüîó Dataset URL: https://huggingface.co/datasets/{REPO_ID}\")\n",
    "    print(f\"\\nüìù Dataset card has been created. You can edit it on HuggingFace Hub.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Upload failed with error:\")\n",
    "    print(f\"  {type(e).__name__}: {e}\")\n",
    "    print(f\"\\nüí° Troubleshooting:\")\n",
    "    print(f\"  1. Check your HuggingFace token is valid\")\n",
    "    print(f\"  2. Ensure you have write permissions\")\n",
    "    print(f\"  3. The repo_id '{REPO_ID}' must match your username\")\n",
    "    print(f\"  4. Try: huggingface-cli login\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18350659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LabAgentSkill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
