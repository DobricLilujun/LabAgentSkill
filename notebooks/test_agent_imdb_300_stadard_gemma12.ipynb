{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf40894",
   "metadata": {},
   "source": [
    "## Init For Agents Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb2b3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Added to sys.path: /home/snt/projects_lujun/LabAgentSkill/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snt/projects_lujun/LabAgentSkill/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - algorithmic-art: Creating algorithmic art using p5.js with seeded randomness and interactive parameter exploration. Use this when users request creating art using code, generative art, algorithmic art, flow fields, or particle systems. Create original algorithmic art rather than copying existing artists' work to avoid copyright violations.\n",
      "  - brand-guidelines: Applies Anthropic's official brand colors and typography to any sort of artifact that may benefit from having Anthropic's look-and-feel. Use it when brand colors or style guidelines, visual formatting, or company design standards apply.\n",
      "  - canvas-design: Create beautiful visual art in .png and .pdf documents using design philosophy. You should use this skill when the user asks to create a poster, piece of art, design, or other static piece. Create original visual designs, never copying existing artists' work to avoid copyright violations.\n",
      "  - doc-coauthoring: Guide users through a structured workflow for co-authoring documentation. Use when user wants to write documentation, proposals, technical specs, decision docs, or similar structured content. This workflow helps users efficiently transfer context, refine content through iteration, and verify the doc works for readers. Trigger when user mentions writing docs, creating proposals, drafting specs, or similar documentation tasks.\n",
      "  - movie-sentiment-analysis: Analyze text sentiment through concise reasoning steps using contextual understanding and keyword cues.\n"
     ]
    }
   ],
   "source": [
    "# Setup: Load environment variables and dependencies\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "project_root = Path.cwd()\n",
    "src_path = project_root / \"src\"\n",
    "\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "    print(f\"✓ Added to sys.path: {src_path}\")\n",
    "\n",
    "from LabAgentSkill import skills_utils\n",
    "from LabAgentSkill.SkillAwareAgent import SkillAwareAgent\n",
    "\n",
    "root_dir = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "env_path = root_dir / \".env\"\n",
    "env = {}\n",
    "\n",
    "if env_path.exists():\n",
    "    for line in env_path.read_text().splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\") or \"=\" not in line:\n",
    "            continue\n",
    "        key, value = line.split(\"=\", 1)\n",
    "        env[key.strip()] = value.strip()\n",
    "\n",
    "# Set API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = env.get(\"OPENAI_API_KEY\", os.environ.get(\"OPENAI_API_KEY\", \"\"))\n",
    "env = Environment(loader=FileSystemLoader('prompts/'))  \n",
    "skills_folder = Path(\"/home/snt/projects_lujun/LabAgentSkill/skillsHub/skills\")\n",
    "all_skills = skills_utils.read_all_skills_metadata(skills_folder)\n",
    "for skill in all_skills:\n",
    "    print(f\"  - {skill['name']}: {skill['description']}\")\n",
    "\n",
    "# model_name = \"gpt-4o-mini\"\n",
    "# base_url = None\n",
    "# model_name = \"google/gemma-3-270m-it\"\n",
    "model_name = \"google/gemma-3-12b-it\"\n",
    "# model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "base_url = \"http://127.0.0.1:8004/v1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c5012e",
   "metadata": {},
   "source": [
    "## Load Data - Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82ea7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset_name = \"Volavion/imdb-sampled-300\"\n",
    "loaded_dataset = load_dataset(dataset_name, split=\"train\")\n",
    "loaded_df = loaded_dataset.to_pandas()\n",
    "loaded_df = loaded_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762a1529",
   "metadata": {},
   "source": [
    "## Select skills "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb474326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from LabAgentSkill.evaluate import get_predicted_label\n",
    "\n",
    "print(f\"Using model: {model_name}\")\n",
    "# Initialize agents\n",
    "agent_skill_aware = SkillAwareAgent(use_chat_history=True, use_trim_messages=True, model=model_name, base_url=base_url)\n",
    "agent_skill_exec_agent = SkillAwareAgent(use_chat_history=True, use_trim_messages=True, model=model_name, base_url=base_url)\n",
    "agent_simple = SkillAwareAgent(use_chat_history=True, use_trim_messages=False, model=model_name, base_url=base_url)\n",
    "\n",
    "p_exec_imdb_temp = env.get_template('p_exec_imdb.jinja')\n",
    "p_skill_select_temp = env.get_template('p_skill_select.jinja')\n",
    "p_skill_discov_temp = env.get_template('p_skill_discov.jinja')\n",
    "p_skill_exec_temp = env.get_template('p_skill_exec.jinja')\n",
    "p_default_system_temp = env.get_template('p_default_system.jinja')\n",
    "\n",
    "# JSONL output path\n",
    "output_dir = \"/home/snt/projects_lujun/LabAgentSkill/assets/results/\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "jsonl_path = output_dir+f\"imdb_300_standard_{model_name.split('/')[-1]}_{timestamp}.jsonl\"\n",
    "print(f\"Results will be saved to: {jsonl_path}\")\n",
    "\n",
    "skill_count = 0\n",
    "count_row = 0\n",
    "if os.path.exists(jsonl_path):\n",
    "    df_exist = pd.read_json(jsonl_path, lines=True)\n",
    "    count_row = len(df_exist)\n",
    "    print(f\"Resume from row: {count_row}\")\n",
    "\n",
    "\n",
    "# Process each sample\n",
    "for idx, row in tqdm( loaded_df.iterrows(), total=len(loaded_df), desc=\"Processing samples\",):\n",
    "\n",
    "    if idx < count_row:\n",
    "        continue\n",
    "    sample_start_time, text, true_label = time.time(), row.text, row.label_name\n",
    "\n",
    "    # Step 1: Skill Selection\n",
    "    print(f\"Start Skill Selection Phase for Sample {idx + 1}/{len(loaded_df)}\")\n",
    "    skill_context = \"\\n\".join([\n",
    "        f\"- **{skill['name']}**: {skill['description']}\"\n",
    "        for skill in all_skills\n",
    "    ])\n",
    "\n",
    "    p_skill_select = p_skill_select_temp.render(SKILL_CONTEXT=skill_context)\n",
    "    p_exec_imdb = p_exec_imdb_temp.render(text=text)\n",
    "    skill_select_resp = agent_skill_aware.chat(user_input=p_exec_imdb, custom_system_prompt=p_skill_select)\n",
    "    selected_skills = skills_utils.parse_skills_from_json_response(json_response=skill_select_resp, skills_hub_dir=skills_folder)\n",
    "\n",
    "    # Track whether \"movie-sentiment-analysis\" was selected in Step 1 \n",
    "    selected_skill_names_step1 = [s[\"name\"] for s in selected_skills]\n",
    "    hit_target_skill = \"movie-sentiment-analysis\" in selected_skill_names_step1 ## This is hard Coded\n",
    "\n",
    "    skill_execution_context = \"\"\n",
    "    for skill_meta in selected_skills:\n",
    "        skill_execution_context += (\n",
    "            f\"SKill {skill_count + 1}: \\n\"\n",
    "            f\"{skill_meta['description']}\\n\"\n",
    "            f\"{'\\n'.join(skill_meta['body'].split('\\n')[1:])}\\n\\n\"\n",
    "        )\n",
    "        skill_count += 1\n",
    "\n",
    "    skill_count_prev = skill_count\n",
    "\n",
    "    # Step 2: Skill Discovery\n",
    "    discovery_rounds = 0\n",
    "    while len(selected_skills) > 0:\n",
    "        p_skill_discov = p_skill_discov_temp.render(SKILL_CONTEXT=skill_execution_context)\n",
    "        skill_discov_resp = agent_skill_exec_agent.chat(user_input=p_skill_discov, custom_system_prompt=p_default_system_temp.render())\n",
    "        selected_skills = skills_utils.parse_skills_from_json_response(json_response=skill_discov_resp, skills_hub_dir=skills_folder)\n",
    "\n",
    "        for skill_meta in selected_skills:\n",
    "            skill_execution_context += (\n",
    "                f\"SKill {skill_count + 1}: \\n\"\n",
    "                f\"{skill_meta['description']}\\n\"\n",
    "                f\"{'\\n'.join(skill_meta['body'].split('\\n')[1:])}\\n\\n\"\n",
    "            )\n",
    "            skill_count += 1\n",
    "        discovery_rounds += 1\n",
    "    new_skills_found = skill_count - skill_count_prev\n",
    "\n",
    "\n",
    "    # print(f\"End of skill discovery phase. Found total of new skills: {new_skills_found}\")\n",
    "    # Step 3: Query Execution\n",
    "    p_skill_exec = p_skill_exec_temp.render(SKILL_CONTEXT=skill_execution_context)\n",
    "    imdb_exec_response = agent_skill_exec_agent.chat(user_input=p_exec_imdb, custom_system_prompt=p_skill_exec)\n",
    "    message_classification = skills_utils.parse_message_from_json_response(imdb_exec_response)\n",
    "    is_correct = true_label.lower() in message_classification.strip().lower()\n",
    "\n",
    "    predicted_label = get_predicted_label(message_classification)\n",
    "    sample_end_time = time.time()\n",
    "    sample_elapsed = sample_end_time - sample_start_time\n",
    "    chat_history_agent_skill_select = agent_skill_aware.get_human_ai_message_history()\n",
    "    chat_history_agent_exec = agent_skill_exec_agent.get_human_ai_message_history()\n",
    "\n",
    "    # Build record and append to JSONL\n",
    "    record = {\n",
    "        \"index\": int(idx),\n",
    "        \"text\": text,\n",
    "        \"true_label\": true_label,\n",
    "        \"predicted_label\": predicted_label,\n",
    "        \"raw_response\": message_classification,\n",
    "        \"correct\": is_correct,\n",
    "        \"selected_skills_step1\": selected_skill_names_step1,\n",
    "        \"hit_target_skill\": hit_target_skill,\n",
    "        \"new_skills_discovered\": new_skills_found,\n",
    "        \"discovery_rounds\": discovery_rounds,\n",
    "        \"elapsed_seconds\": round(sample_elapsed, 4),\n",
    "        \"model\": model_name,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"chat_history_agent_skill_select\": chat_history_agent_skill_select,\n",
    "        \"chat_history_agent_exec\": chat_history_agent_exec,\n",
    "        \"task_type\": \"agent_skill_based\"\n",
    "        \n",
    "    }\n",
    "\n",
    "    dataframe_record = pd.DataFrame([record])\n",
    "    dataframe_record.to_json(jsonl_path, orient=\"records\", lines=True, mode=\"a\" if os.path.exists(jsonl_path) else \"w\")\n",
    "    agent_skill_aware.clear_history()\n",
    "    agent_skill_exec_agent.clear_history()\n",
    "\n",
    "    ######################################################################################################################################\n",
    "    sample_start_time, text, true_label = time.time(), row.text, row.label_name\n",
    "\n",
    "    p_exec_imdb = p_exec_imdb_temp.render(text=text)\n",
    "    p_exec_imdb_sys = p_default_system_temp.render()\n",
    "    imdb_exec_response = agent_simple.chat(user_input=p_exec_imdb, custom_system_prompt=p_exec_imdb_sys)\n",
    "    message_classification = skills_utils.parse_message_from_json_response(imdb_exec_response)\n",
    "    is_correct = true_label.lower() in message_classification.strip().lower()\n",
    "\n",
    "    predicted_label = get_predicted_label(message_classification)\n",
    "    sample_end_time = time.time()\n",
    "    sample_elapsed = sample_end_time - sample_start_time\n",
    "    chat_history_agent_exec = agent_simple.get_human_ai_message_history()\n",
    "\n",
    "    # Build record and append to JSONL\n",
    "    record = {\n",
    "        \"index\": int(idx),\n",
    "        \"text\": text,\n",
    "        \"true_label\": true_label,\n",
    "        \"predicted_label\": predicted_label,\n",
    "        \"raw_response\": message_classification,\n",
    "        \"correct\": is_correct,\n",
    "        \"selected_skills_step1\": \"\",\n",
    "        \"hit_target_skill\": \"\",\n",
    "        \"new_skills_discovered\": \"\",\n",
    "        \"discovery_rounds\": \"\",\n",
    "        \"elapsed_seconds\": round(sample_elapsed, 4),\n",
    "        \"model\": model_name,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"chat_history_agent_skill_select\": \"\",\n",
    "        \"chat_history_agent_exec\": chat_history_agent_exec,\n",
    "        \"task_type\": \"agent_simple\"\n",
    "        \n",
    "    }\n",
    "\n",
    "    dataframe_record = pd.DataFrame([record])\n",
    "    dataframe_record.to_json(jsonl_path, orient=\"records\", lines=True, mode=\"a\" if os.path.exists(jsonl_path) else \"w\")\n",
    "    agent_simple.clear_history()\n",
    "\n",
    "    ######################################################################################################################################\n",
    "    sample_start_time, text, true_label = time.time(), row.text, row.label_name\n",
    "    skill_context_all =  \"The following are skills informaiton you can use as a reference for user request:\\n\".join([\n",
    "        f\"- **{skill['name']}**:\\n {skill['description']} **:\\n {skill['body']}\"\n",
    "        for skill in all_skills\n",
    "    ])\n",
    "    p_exec_imdb = p_exec_imdb_temp.render(text= text + skill_context_all)\n",
    "    p_exec_imdb_sys = p_default_system_temp.render()\n",
    "\n",
    "    imdb_exec_response = agent_simple.chat(user_input=p_exec_imdb, custom_system_prompt=p_exec_imdb_sys)\n",
    "    message_classification = skills_utils.parse_message_from_json_response(imdb_exec_response)\n",
    "    is_correct = true_label.lower() in message_classification.strip().lower()\n",
    "\n",
    "    predicted_label = get_predicted_label(message_classification)\n",
    "    sample_end_time = time.time()\n",
    "    sample_elapsed = sample_end_time - sample_start_time\n",
    "    chat_history_agent_exec = agent_simple.get_human_ai_message_history()\n",
    "\n",
    "    # Build record and append to JSONL\n",
    "    record = {\n",
    "        \"index\": int(idx),\n",
    "        \"text\": text,\n",
    "        \"true_label\": true_label,\n",
    "        \"predicted_label\": predicted_label,\n",
    "        \"raw_response\": message_classification,\n",
    "        \"correct\": is_correct,\n",
    "        \"selected_skills_step1\": \"\",\n",
    "        \"hit_target_skill\": \"\",\n",
    "        \"new_skills_discovered\": \"\",\n",
    "        \"discovery_rounds\": \"\",\n",
    "        \"elapsed_seconds\": round(sample_elapsed, 4),\n",
    "        \"model\": model_name,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"chat_history_agent_skill_select\": \"\",\n",
    "        \"chat_history_agent_exec\": chat_history_agent_exec,\n",
    "        \"task_type\": \"agent_skill_full_context\"\n",
    "        \n",
    "    }\n",
    "\n",
    "    dataframe_record = pd.DataFrame([record])\n",
    "    dataframe_record.to_json(jsonl_path, orient=\"records\", lines=True, mode=\"a\" if os.path.exists(jsonl_path) else \"w\")\n",
    "    agent_simple.clear_history()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"All {len(loaded_df)} samples processed. Results saved to: {jsonl_path}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3914661d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_simple 0.9650 0.9649 0.0000 0.4407 12.6927\n",
      "agent_skill_based 0.9676 0.9676 1.0000 0.2454 7.0685\n",
      "agent_skill_full_context 0.9690 0.9691 0.0000 0.8742 25.1780\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score  # F1 supports macro/weighted averages [web:2]\n",
    "\n",
    "jsonl_path = \"assets/results/imdb_300_standard_gemma-3-12b-it_20260212_003816.jsonl\"\n",
    "results_df = pd.read_json(jsonl_path, lines=True)\n",
    "\n",
    "TARGET = \"movie-sentiment-analysis\"\n",
    "\n",
    "def calc_hit_target_skill(row) -> bool:\n",
    "    lst = row.get(\"chat_history_agent_skill_select\", \"\")\n",
    "    if not lst:\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        obj = lst[1] \n",
    "        content = (obj or {}).get(\"content\", \"\")\n",
    "    except (IndexError, TypeError, AttributeError):\n",
    "        return False\n",
    "\n",
    "    return TARGET in str(content).lower()\n",
    "\n",
    "results_df[\"hit_target_skill\"] = results_df.apply(calc_hit_target_skill, axis=1)\n",
    "\n",
    "ESTIMATED_GPU_RAM_GB = 28.80\n",
    "\n",
    "for task_type, g in results_df.groupby(\"task_type\", dropna=False):\n",
    "\n",
    "    # --- ACC / F1: exclude \"unknown\" predictions ---\n",
    "    pred_lower = g[\"predicted_label\"].astype(str).str.lower()\n",
    "    valid_mask = pred_lower.ne(\"unknown\")\n",
    "    valid_df = g[valid_mask]\n",
    "    unknown_count = int((~valid_mask).sum())\n",
    "\n",
    "    if len(valid_df) > 0:\n",
    "        y_true = valid_df[\"true_label\"].astype(str).str.lower()\n",
    "        y_pred = valid_df[\"predicted_label\"].astype(str).str.lower()\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        f1_macro = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)      # macro avg [web:2]\n",
    "        f1_weighted = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)  # weighted avg [web:2]\n",
    "        correct = int((y_true == y_pred).sum())\n",
    "        denom = len(valid_df)\n",
    "    else:\n",
    "        acc = float(\"nan\")\n",
    "        f1_macro = float(\"nan\")\n",
    "        f1_weighted = float(\"nan\")\n",
    "        correct = 0\n",
    "        denom = 0\n",
    "\n",
    "    # --- Hit Rate: count non-empty hit_target_skill ---\n",
    "    hit_count = int(g[\"hit_target_skill\"].fillna(\"\").astype(str).eq(\"True\").sum())\n",
    "    hit_rate = hit_count / len(g) if len(g) > 0 else float(\"nan\")\n",
    "\n",
    "    # --- VRAM-Hours (GB·h): VRAM(GB) * time(hours) ---\n",
    "    total_time_sec = g[\"elapsed_seconds\"].fillna(0).astype(float).sum()\n",
    "    total_minutes = (total_time_sec / 60.0)\n",
    "    total_vram_minutes = total_minutes * ESTIMATED_GPU_RAM_GB\n",
    "    avg_minutes= total_minutes / len(g) if len(g) > 0 else float(\"nan\")\n",
    "    avg_vram_minutes = total_vram_minutes / len(g) if len(g) > 0 else float(\"nan\")\n",
    "    # --- Print only the requested metrics ---\n",
    "    # print(f\"[task_type={task_type}] \"\n",
    "    #       f\"ACC={acc:.4f} ({correct}/{denom}, unknown_excluded={unknown_count}) | \"\n",
    "    #       f\"F1_weighted={f1_weighted:.4f} | \"\n",
    "    #       f\"HitRate={hit_rate:.4f} ({hit_count}/{len(g)}) | \"\n",
    "    #       f\"AvgHours={avg_hours:.4f} | AvgVRAM-Hours={avg_vram_hours:.4f} GB·h\"\n",
    "    # )\n",
    "\n",
    "    print (f\"{task_type} {acc:.4f} {f1_weighted:.4f} {hit_rate:.4f} {avg_minutes:.4f} {avg_vram_minutes:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00bf5586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hit_target_skill\n",
       "         600\n",
       "False    300\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.hit_target_skill.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23ba778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb661c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LabAgentSkill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
