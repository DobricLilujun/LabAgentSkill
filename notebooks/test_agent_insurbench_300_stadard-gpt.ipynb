{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf40894",
   "metadata": {},
   "source": [
    "## Init For Agents Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb2b3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Added to sys.path: /home/snt/projects_lujun/LabAgentSkill/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snt/projects_lujun/LabAgentSkill/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - XBRL-tag-classification: Classify financial text into specific XBRL tags by analyzing semantic cues, context, and category boundaries.\n",
      "  - algorithmic-art: Creating algorithmic art using p5.js with seeded randomness and interactive parameter exploration. Use this when users request creating art using code, generative art, algorithmic art, flow fields, or particle systems. Create original algorithmic art rather than copying existing artists' work to avoid copyright violations.\n",
      "  - brand-guidelines: Applies Anthropic's official brand colors and typography to any sort of artifact that may benefit from having Anthropic's look-and-feel. Use it when brand colors or style guidelines, visual formatting, or company design standards apply.\n",
      "  - canvas-design: Create beautiful visual art in .png and .pdf documents using design philosophy. You should use this skill when the user asks to create a poster, piece of art, design, or other static piece. Create original visual designs, never copying existing artists' work to avoid copyright violations.\n",
      "  - doc-coauthoring: Guide users through a structured workflow for co-authoring documentation. Use when user wants to write documentation, proposals, technical specs, decision docs, or similar structured content. This workflow helps users efficiently transfer context, refine content through iteration, and verify the doc works for readers. Trigger when user mentions writing docs, creating proposals, drafting specs, or similar documentation tasks.\n",
      "  - insurance-mail-triage: Triage long email threads for an insurance context, identify the most recent actionable message, extract key context, infer intent (e.g., missing documents, follow-up/reminder, payment, status), and decide whether to reply or take further action.\n",
      "  - movie-sentiment-analysis: Analyze text sentiment through concise reasoning steps using contextual understanding and keyword cues.\n"
     ]
    }
   ],
   "source": [
    "# Setup: Load environment variables and dependencies\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "project_root = Path.cwd()\n",
    "src_path = project_root / \"src\"\n",
    "\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "    print(f\"✓ Added to sys.path: {src_path}\")\n",
    "\n",
    "from LabAgentSkill import skills_utils\n",
    "from LabAgentSkill.SkillAwareAgent import SkillAwareAgent\n",
    "\n",
    "root_dir = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "env_path = root_dir / \".env\"\n",
    "env = {}\n",
    "\n",
    "if env_path.exists():\n",
    "    for line in env_path.read_text().splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\") or \"=\" not in line:\n",
    "            continue\n",
    "        key, value = line.split(\"=\", 1)\n",
    "        env[key.strip()] = value.strip()\n",
    "\n",
    "# Set API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = env.get(\"OPENAI_API_KEY\", os.environ.get(\"OPENAI_API_KEY\", \"\"))\n",
    "env = Environment(loader=FileSystemLoader('prompts/'))  \n",
    "skills_folder = Path(\"/home/snt/projects_lujun/LabAgentSkill/skillsHub/skills_insurBench\")\n",
    "all_skills = skills_utils.read_all_skills_metadata(skills_folder)\n",
    "for skill in all_skills:\n",
    "    print(f\"  - {skill['name']}: {skill['description']}\")\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "base_url = None\n",
    "\n",
    "\n",
    "# model_name = \"google/gemma-3-270m-it\"\n",
    "# model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "# base_url = \"http://127.0.0.1:8001/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c5012e",
   "metadata": {},
   "source": [
    "## Load Data - Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82ea7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset_name = \"/home/snt/projects_lujun/LabAgentSkill/assets/datasets/insureBench.jsonl\"\n",
    "loaded_df = pd.read_json(dataset_name, lines=True)\n",
    "loaded_df = loaded_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762a1529",
   "metadata": {},
   "source": [
    "## Select skills "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb474326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-4o-mini\n",
      "✓ SkillAwareAgent initialized\n",
      "  Model: gpt-4o-mini\n",
      "  Chat History: ENABLED ✓\n",
      "  Trim Messages: ENABLED ✓\n",
      "✓ SkillAwareAgent initialized\n",
      "  Model: gpt-4o-mini\n",
      "  Chat History: ENABLED ✓\n",
      "  Trim Messages: ENABLED ✓\n",
      "✓ SkillAwareAgent initialized\n",
      "  Model: gpt-4o-mini\n",
      "  Chat History: ENABLED ✓\n",
      "  Trim Messages: DISABLED ✗\n",
      "Results will be saved to: /home/snt/projects_lujun/LabAgentSkill/assets/results/insurBench_standard_gpt-4o-mini_20260212_163914.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples: 100%|██████████| 4/4 [01:14<00:00, 18.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "All 4 samples processed. Results saved to: /home/snt/projects_lujun/LabAgentSkill/assets/results/insurBench_standard_gpt-4o-mini_20260212_163914.jsonl\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from LabAgentSkill.evaluate import get_insurBench_predicted_label, get_predicted_label, get_prediction_XBRL_TAGS\n",
    "\n",
    "print(f\"Using model: {model_name}\")\n",
    "# Initialize agents\n",
    "agent_skill_aware = SkillAwareAgent(use_chat_history=True, use_trim_messages=True, model=model_name, base_url=base_url)\n",
    "agent_skill_exec_agent = SkillAwareAgent(use_chat_history=True, use_trim_messages=True, model=model_name, base_url=base_url)\n",
    "agent_simple = SkillAwareAgent(use_chat_history=True, use_trim_messages=False, model=model_name, base_url=base_url)\n",
    "\n",
    "p_exec_insurBench_temp = env.get_template('p_exec_insurBench.jinja')\n",
    "p_skill_select_temp = env.get_template('p_skill_select.jinja')\n",
    "p_skill_discov_temp = env.get_template('p_skill_discov.jinja')\n",
    "p_default_system_temp = env.get_template('p_default_system.jinja')\n",
    "p_skill_exec_temp = env.get_template('p_skill_exec.jinja')\n",
    "\n",
    "# JSONL output path\n",
    "output_dir = \"/home/snt/projects_lujun/LabAgentSkill/assets/results/\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "jsonl_path = output_dir+f\"insurBench_standard_{model_name.split('/')[-1]}_{timestamp}.jsonl\"\n",
    "print(f\"Results will be saved to: {jsonl_path}\")\n",
    "\n",
    "skill_count = 0\n",
    "count_row = 0\n",
    "if os.path.exists(jsonl_path):\n",
    "    df_exist = pd.read_json(jsonl_path, lines=True)\n",
    "    count_row = len(df_exist)\n",
    "    print(f\"Resume from row: {count_row}\")\n",
    "\n",
    "\n",
    "# Process each sample\n",
    "for idx, row in tqdm( loaded_df.iterrows(), total=len(loaded_df), desc=\"Processing samples\",):\n",
    "\n",
    "    if idx < count_row:\n",
    "        continue\n",
    "    \n",
    "    sample_start_time, email_history, cls_label = time.time(), row.content, row.cls_label\n",
    "    true_label = {\"Non\": \"NO\", \"Oui\": \"YES\"}.get(cls_label, cls_label)\n",
    "\n",
    "    # Step 1: Skill Selection\n",
    "    # print(f\"Start Skill Selection Phase for Sample {idx + 1}/{len(loaded_df)}\")\n",
    "    skill_context = \"\\n\".join([\n",
    "        f\"- **{skill['name']}**: {skill['description']}\"\n",
    "        for skill in all_skills\n",
    "    ])\n",
    "\n",
    "    p_skill_select = p_skill_select_temp.render(SKILL_CONTEXT=skill_context)\n",
    "    p_exec_insurBench = p_exec_insurBench_temp.render(EMAIL_HISTORY = email_history)\n",
    "    skill_select_resp = agent_skill_aware.chat(user_input=p_exec_insurBench, custom_system_prompt=p_skill_select)\n",
    "    selected_skills = skills_utils.parse_skills_from_json_response(json_response=skill_select_resp, skills_hub_dir=skills_folder)\n",
    "\n",
    "    # Track whether \"movie-sentiment-analysis\" was selected in Step 1 \n",
    "    selected_skill_names_step1 = [s[\"name\"] for s in selected_skills]\n",
    "    hit_target_skill = \"insurance-mail-triage\".lower() in skill_select_resp.lower() ## This is hard Coded\n",
    "\n",
    "    skill_execution_context = \"\"\n",
    "    for skill_meta in selected_skills:\n",
    "        skill_execution_context += (\n",
    "            f\"SKill {skill_count + 1}: \\n\"\n",
    "            f\"{skill_meta['description']}\\n\"\n",
    "            f\"{'\\n'.join(skill_meta['body'].split('\\n')[1:])}\\n\\n\"\n",
    "        )\n",
    "        skill_count += 1\n",
    "\n",
    "    skill_count_prev = skill_count\n",
    "\n",
    "    # Step 2: Skill Discovery\n",
    "    discovery_rounds = 0\n",
    "    while len(selected_skills) > 0:\n",
    "        p_skill_discov = p_skill_discov_temp.render(SKILL_CONTEXT=skill_execution_context)\n",
    "        skill_discov_resp = agent_skill_exec_agent.chat(user_input=p_skill_discov, custom_system_prompt=p_default_system_temp.render())\n",
    "        selected_skills = skills_utils.parse_skills_from_json_response(json_response=skill_discov_resp, skills_hub_dir=skills_folder)\n",
    "\n",
    "        for skill_meta in selected_skills:\n",
    "            skill_execution_context += (\n",
    "                f\"SKill {skill_count + 1}: \\n\"\n",
    "                f\"{skill_meta['description']}\\n\"\n",
    "                f\"{'\\n'.join(skill_meta['body'].split('\\n')[1:])}\\n\\n\"\n",
    "            )\n",
    "            skill_count += 1\n",
    "        discovery_rounds += 1\n",
    "    new_skills_found = skill_count - skill_count_prev\n",
    "\n",
    "\n",
    "    # print(f\"End of skill discovery phase. Found total of new skills: {new_skills_found}\")\n",
    "    # Step 3: Query Execution\n",
    "    p_exec_insurBench_sys = p_skill_exec_temp.render(SKILL_CONTEXT=skill_execution_context)\n",
    "    insurBench_exec_response = agent_skill_exec_agent.chat(user_input=p_exec_insurBench, custom_system_prompt=p_exec_insurBench_sys)\n",
    "    message_classification = skills_utils.parse_message_from_json_response(insurBench_exec_response)\n",
    "    is_correct = true_label.lower() in message_classification.strip().lower()\n",
    "\n",
    "    predicted_label = get_insurBench_predicted_label(message_classification)\n",
    "    sample_end_time = time.time()\n",
    "    sample_elapsed = sample_end_time - sample_start_time\n",
    "    chat_history_agent_skill_select = agent_skill_aware.get_human_ai_message_history()\n",
    "    chat_history_agent_exec = agent_skill_exec_agent.get_human_ai_message_history()\n",
    "\n",
    "    # Build record and append to JSONL\n",
    "    record = {\n",
    "        \"index\": int(idx),\n",
    "        \"email_history\": email_history,\n",
    "        \"true_label\": true_label,\n",
    "        \"predicted_label\": predicted_label,\n",
    "        \"raw_response\": message_classification,\n",
    "        \"correct\": is_correct,\n",
    "        \"selected_skills_step1\": selected_skill_names_step1,\n",
    "        \"hit_target_skill\": hit_target_skill,\n",
    "        \"new_skills_discovered\": new_skills_found,\n",
    "        \"discovery_rounds\": discovery_rounds,\n",
    "        \"elapsed_seconds\": round(sample_elapsed, 4),\n",
    "        \"model\": model_name,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"chat_history_agent_skill_select\": chat_history_agent_skill_select,\n",
    "        \"chat_history_agent_exec\": chat_history_agent_exec,\n",
    "        \"task_type\": \"agent_skill_based\"\n",
    "        \n",
    "    }\n",
    "\n",
    "    dataframe_record = pd.DataFrame([record])\n",
    "    dataframe_record.to_json(jsonl_path, orient=\"records\", lines=True, mode=\"a\" if os.path.exists(jsonl_path) else \"w\")\n",
    "    agent_skill_aware.clear_history()\n",
    "    agent_skill_exec_agent.clear_history()\n",
    "\n",
    "    ######################################################################################################################################\n",
    "    \n",
    "    sample_start_time, email_history, cls_label = time.time(), row.content, row.cls_label\n",
    "    true_label = {\"Non\": \"NO\", \"Oui\": \"YES\"}.get(cls_label, cls_label)\n",
    "    p_exec_insurBench_sys = p_default_system_temp.render()\n",
    "    insurBench_exec_response = agent_simple.chat(user_input=p_exec_insurBench, custom_system_prompt=p_exec_insurBench_sys)\n",
    "    message_classification = skills_utils.parse_message_from_json_response(insurBench_exec_response)\n",
    "    is_correct = true_label.lower() in message_classification.strip().lower()\n",
    "\n",
    "    predicted_label = get_prediction_XBRL_TAGS(message_classification)\n",
    "    sample_end_time = time.time()\n",
    "    sample_elapsed = sample_end_time - sample_start_time\n",
    "    chat_history_agent_exec = agent_simple.get_human_ai_message_history()\n",
    "\n",
    "    # Build record and append to JSONL\n",
    "    record = {\n",
    "        \"index\": int(idx),\n",
    "        \"email_history\": email_history,\n",
    "        \"true_label\": true_label,\n",
    "        \"predicted_label\": predicted_label,\n",
    "        \"raw_response\": message_classification,\n",
    "        \"correct\": is_correct,\n",
    "        \"selected_skills_step1\": \"\",\n",
    "        \"hit_target_skill\": \"\",\n",
    "        \"new_skills_discovered\": \"\",\n",
    "        \"discovery_rounds\": \"\",\n",
    "        \"elapsed_seconds\": round(sample_elapsed, 4),\n",
    "        \"model\": model_name,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"chat_history_agent_skill_select\": \"\",\n",
    "        \"chat_history_agent_exec\": chat_history_agent_exec,\n",
    "        \"task_type\": \"agent_simple\"\n",
    "        \n",
    "    }\n",
    "\n",
    "    dataframe_record = pd.DataFrame([record])\n",
    "    dataframe_record.to_json(jsonl_path, orient=\"records\", lines=True, mode=\"a\" if os.path.exists(jsonl_path) else \"w\")\n",
    "    agent_simple.clear_history()\n",
    "\n",
    "\n",
    "    ######################################################################################################################################\n",
    "    sample_start_time, email_history, cls_label = time.time(), row.content, row.cls_Label\n",
    "    true_label = {\"Non\": \"NO\", \"Oui\": \"YES\"}.get(cls_label, cls_label)\n",
    "    skill_context_all =  \"The following are skills informaiton you can use as a reference for user request:\\n\".join([\n",
    "        f\"- **{skill['name']}**:\\n {skill['description']} **:\\n {skill['body']}\"\n",
    "        for skill in all_skills\n",
    "    ])\n",
    "    p_exec_insurBench = p_exec_insurBench_temp.render(EMAIL_HISTORY = email_history + skill_context_all)\n",
    "    p_exec_insurBench_sys = p_default_system_temp.render()\n",
    "\n",
    "    insurBench_exec_response = agent_simple.chat(user_input=p_exec_insurBench, custom_system_prompt=p_exec_insurBench_sys)\n",
    "    message_classification = skills_utils.parse_message_from_json_response(insurBench_exec_response)\n",
    "    is_correct = true_label.lower() in message_classification.strip().lower()\n",
    "\n",
    "    predicted_label = get_insurBench_predicted_label(message_classification)\n",
    "    sample_end_time = time.time()\n",
    "    sample_elapsed = sample_end_time - sample_start_time\n",
    "    chat_history_agent_exec = agent_simple.get_human_ai_message_history()\n",
    "\n",
    "    # Build record and append to JSONL\n",
    "    record = {\n",
    "        \"index\": int(idx),\n",
    "        \"email_history\": email_history,\n",
    "        \"true_label\": true_label,\n",
    "        \"predicted_label\": predicted_label,\n",
    "        \"raw_response\": message_classification,\n",
    "        \"correct\": is_correct,\n",
    "        \"selected_skills_step1\": \"\",\n",
    "        \"hit_target_skill\": \"\",\n",
    "        \"new_skills_discovered\": \"\",\n",
    "        \"discovery_rounds\": \"\",\n",
    "        \"elapsed_seconds\": round(sample_elapsed, 4),\n",
    "        \"model\": model_name,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"chat_history_agent_skill_select\": \"\",\n",
    "        \"chat_history_agent_exec\": chat_history_agent_exec,\n",
    "        \"task_type\": \"agent_skill_full_context\"\n",
    "        \n",
    "    }\n",
    "\n",
    "    dataframe_record = pd.DataFrame([record])\n",
    "    dataframe_record.to_json(jsonl_path, orient=\"records\", lines=True, mode=\"a\" if os.path.exists(jsonl_path) else \"w\")\n",
    "    agent_simple.clear_history()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"All {len(loaded_df)} samples processed. Results saved to: {jsonl_path}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3914661d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File /home/snt/projects_lujun/LabAgentSkill/assets/results/insurBench_standard_Qwen3-30B-A3B-Instruct-2507_20260212_121226.jsonl does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects_lujun/LabAgentSkill/.venv/lib/python3.12/site-packages/pandas/io/json/_json.py:948\u001b[39m, in \u001b[36mJsonReader._get_data_from_filepath\u001b[39m\u001b[34m(self, filepath_or_buffer)\u001b[39m\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m948\u001b[39m     \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects_lujun/LabAgentSkill/.venv/lib/python3.12/site-packages/pandas/io/common.py:926\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    925\u001b[39m     \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m     handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m        \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    934\u001b[39m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/snt/projects_lujun/LabAgentSkill/assets/results/insurBench_standard_Qwen3-30B-A3B-Instruct-2507_20260212_121226.jsonl'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, f1_score  \u001b[38;5;66;03m# F1 supports macro/weighted averages [web:2]\u001b[39;00m\n\u001b[32m      4\u001b[39m jsonl_path = \u001b[33m\"\u001b[39m\u001b[33m/home/snt/projects_lujun/LabAgentSkill/assets/results/insurBench_standard_Qwen3-30B-A3B-Instruct-2507_20260212_121226.jsonl\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m results_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjsonl_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m TARGET = \u001b[33m\"\u001b[39m\u001b[33mXBRL-tag-classification\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalc_hit_target_skill\u001b[39m(row) -> \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects_lujun/LabAgentSkill/.venv/lib/python3.12/site-packages/pandas/io/json/_json.py:829\u001b[39m, in \u001b[36mread_json\u001b[39m\u001b[34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[39m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient != \u001b[33m\"\u001b[39m\u001b[33mtable\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    827\u001b[39m     convert_axes = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m json_reader = \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[32m    851\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects_lujun/LabAgentSkill/.venv/lib/python3.12/site-packages/pandas/io/json/_json.py:931\u001b[39m, in \u001b[36mJsonReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[39m\n\u001b[32m    929\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = filepath_or_buffer\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mujson\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m     \u001b[38;5;66;03m# If self.chunksize, we prepare the data for the `__next__` method.\u001b[39;00m\n\u001b[32m    933\u001b[39m     \u001b[38;5;66;03m# Otherwise, we read it into memory for the `read` method.\u001b[39;00m\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.chunksize \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nrows):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects_lujun/LabAgentSkill/.venv/lib/python3.12/site-packages/pandas/io/json/_json.py:957\u001b[39m, in \u001b[36mJsonReader._get_data_from_filepath\u001b[39m\u001b[34m(self, filepath_or_buffer)\u001b[39m\n\u001b[32m    948\u001b[39m     \u001b[38;5;28mself\u001b[39m.handles = get_handle(\n\u001b[32m    949\u001b[39m         filepath_or_buffer,\n\u001b[32m    950\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m         errors=\u001b[38;5;28mself\u001b[39m.encoding_errors,\n\u001b[32m    955\u001b[39m     )\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[32m    958\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    959\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    960\u001b[39m filepath_or_buffer = \u001b[38;5;28mself\u001b[39m.handles.handle\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m filepath_or_buffer\n",
      "\u001b[31mFileNotFoundError\u001b[39m: File /home/snt/projects_lujun/LabAgentSkill/assets/results/insurBench_standard_Qwen3-30B-A3B-Instruct-2507_20260212_121226.jsonl does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score  # F1 supports macro/weighted averages [web:2]\n",
    "\n",
    "jsonl_path = \"/home/snt/projects_lujun/LabAgentSkill/assets/results/insurBench_standard_Qwen3-30B-A3B-Instruct-2507_20260212_121226.jsonl\"\n",
    "results_df = pd.read_json(jsonl_path, lines=True)\n",
    "TARGET = \"XBRL-tag-classification\"\n",
    "\n",
    "def calc_hit_target_skill(row) -> bool:\n",
    "    lst = row.get(\"chat_history_agent_skill_select\", \"\")\n",
    "    if not lst:\n",
    "        return False\n",
    "    try:\n",
    "        obj = lst[1] \n",
    "        content = (obj or {}).get(\"content\", \"\")\n",
    "    except (IndexError, TypeError, AttributeError):\n",
    "        return False\n",
    "\n",
    "    return TARGET.lower() in str(content).lower()\n",
    "\n",
    "results_df[\"hit_target_skill\"] = results_df.apply(calc_hit_target_skill, axis=1)\n",
    "ESTIMATED_GPU_RAM_GB = 100\n",
    "\n",
    "for task_type, g in results_df.groupby(\"task_type\", dropna=False):\n",
    "\n",
    "    # --- ACC / F1: exclude \"unknown\" predictions ---\n",
    "    pred_lower = g[\"predicted_label\"].astype(str).str.lower()\n",
    "    valid_mask = pred_lower.ne(\"unknown\")\n",
    "    valid_df = g[valid_mask]\n",
    "    unknown_count = int((~valid_mask).sum())\n",
    "\n",
    "    if len(valid_df) > 0:\n",
    "        y_true = valid_df[\"true_label\"].astype(str).str.lower()\n",
    "        y_pred = valid_df[\"predicted_label\"].astype(str).str.lower()\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        f1_macro = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)      # macro avg [web:2]\n",
    "        f1_weighted = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)  # weighted avg [web:2]\n",
    "        correct = int((y_true == y_pred).sum())\n",
    "        denom = len(valid_df)\n",
    "    else:\n",
    "        acc = float(\"0.0000\")\n",
    "        f1_macro = float(\"0.0000\")\n",
    "        f1_weighted = float(\"0.0000\")\n",
    "        correct = 0\n",
    "        denom = 0\n",
    "\n",
    "    # --- Hit Rate: count non-empty hit_target_skill ---\n",
    "    hit_count = int(g[\"hit_target_skill\"].fillna(\"\").astype(str).eq(\"True\").sum())\n",
    "    hit_rate = hit_count / len(g) if len(g) > 0 else float(\"nan\")\n",
    "\n",
    "    # --- VRAM-Hours (GB·h): VRAM(GB) * time(hours) ---\n",
    "    total_time_sec = g[\"elapsed_seconds\"].fillna(0).astype(float).sum()\n",
    "    total_minutes = (total_time_sec / 60.0)\n",
    "    total_vram_minutes = total_minutes * ESTIMATED_GPU_RAM_GB\n",
    "    avg_minutes= total_minutes / len(g) if len(g) > 0 else float(\"nan\")\n",
    "    avg_vram_minutes = total_vram_minutes / len(g) if len(g) > 0 else float(\"nan\")\n",
    "    # --- Print only the requested metrics ---\n",
    "    # print(f\"[task_type={task_type}] \"\n",
    "    #       f\"ACC={acc:.4f} ({correct}/{denom}, unknown_excluded={unknown_count}) | \"\n",
    "    #       f\"F1_weighted={f1_weighted:.4f} | \"\n",
    "    #       f\"HitRate={hit_rate:.4f} ({hit_count}/{len(g)}) | \"\n",
    "    #       f\"AvgHours={avg_hours:.4f} | AvgVRAM-Hours={avg_vram_hours:.4f} GB·h\"\n",
    "    # )\n",
    "\n",
    "    print (f\"{task_type} {acc:.4f} {f1_weighted:.4f} {hit_rate:.4f} {avg_minutes:.4f} {avg_vram_minutes:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f3a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79fbda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LabAgentSkill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
